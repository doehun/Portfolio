In worksheet 4, question 3, asks: "If you had to reduce the dimensions of this data down to 2 variables, which variables would you choose?"   

The solution says Principal Component 1 and Principal Component 2.  

However, why wouldn't you say the variables Petal_Length and Sepal_Width, which appear to be most closely associated with those Principal Components?  I guess I'm just hung up on the word "variables" in the original equation which led me to believe the answer should be 2 of the 4 listed variables.  :thinking_face:
<@U1L93SMGF> When you use PCA to reduce the data, the principal components become your new variables in the space created by the new basis vectors.
I thought that might be the case, but then I wasn't sure as the word "variable" was used to refer to non-principal components in a previous question.  It all gets a little confusing for me.  Thanks <@U1KRB11QC>
On the same worksheet, for the question "observations that have larger scores on PC3 are somewhat likely to have larger/smaller than average sepal length?" Can someone explain to me why the answer is smaller ?
<@U1L93SMGF> i kind of asked dr. race the same question and she was saying if you dropped petal_length and sepal_width, it's essentially like you have taken those variables out completely out of your analysis and you don't really want that.....the principal components on the other hand are a combination of your 4 variables so by dropping the principal component, you would be losing some information across the board and not the variables sepal width petal length completely
<@U1L9DD1NY> If I remember correctly, I think I put smaller because PC3 and Sepal Length have a negative correlation. So if PC3 is larger, Sepal Length is probably smaller
<@U1L9DD1NY> i think its because that value is negative and correlation matrix is standardized data so you are looking at how far you are away from the mean but im not sure though
Okay thanks! <@U1KRE1L9M> <@U1KSBCBFG> 
This site was helpful to me in getting a more conceptual understanding of PCA: <http://setosa.io/ev/principal-component-analysis/>
FYI there is a quiz due tonight, but there is no quiz associated with today's lecture
If you were wondering: "gene expression" means whether a particular gene is turned up or down.  Each gene contains the instructions for building a protein.  So if a gene is highly expressed it is building a lot of that protein, and if expression is low, it's not building much of it.  (Sorry, I couldn't resist!)  Bio folks, does this sound reasonable?
Thanks <@U1KRNTXL5> that helps add some context to the problem.
in the chicken example we went through in class, when we changed the values of diet to factors, does anyone know the reasoning for choosing those specific values? Why did Dr Race use 5, 6, 8, and 9 instead of 1, 2, 3, and 4?
Those are actually the number of times each value of the factor is repeated! She puts each value inside a rep() function, which means repeat, creating a vector containing each diet repeated a pre-known number of times.
ah, that makes a lot more sense now. thank you!
so what is a good way to group our variables, <@U1KRNTXL5> <@U1L3G0YRJ> ? we need to group them to make pretty charts... since the color of the dots on the graph would depend on the group... any clues? :smile:
Check the last column of the data frame!
Do we need to know the stuff from the primer for Thursday?  E.g., we did a lot more with least squares regression in the primer than in the lectures... are those on-limits for questions?
My understanding is no primer stuff
Does anyone know if we will be asked to do the actual calculation to translate our PCs back into terms of the original variables for PCR on the test, or should we just understand how it works?
<https://quizlet.com/154414436/iaa-linear-algebra-flash-cards/> (This includes some of the questions from quizzes/worksheets, and questions I generated from my notes, I tried to include as much as I could!)
<@U1KRQLFLY>: I'm thinking we won't have to know the math because even when she was going over it in class it basically went "There's a lot of math, but your computer does it for you so you don't have to worry too much"
If I'm remembering correctly. 
And thanks <@U1L41DF9D> ! These are so helpful. 
<@U1L7E8GSU> <@U1KRQLFLY> Rachel, your right! She just wants you to know that you will be doing replacement math or using PROC PLS, but with PROC PLS you have to principal components in order so you wouldn't be able to do principal components 1, 3,4, and &amp;6, you would have to have 1-6 principal components in the PROC PLS (if you want only those principal components then you'd have to do the replacement math for it). I think thats all we have to know - not necessarily how to do the replacement math.
Possibly silly question...I am looking at the worksheet #5, question 8c. How do we know the total variance is 4 in this case? Is the total variance always equal to the number of variables?
Yes for correlation not covariance <@U1KRHCR7T> 
for either correlation or covariance you can add up the eigenvalues and that will equal total variance
Thanks <@U1L9DD1NY> and <@U1L914KNJ>
<@U1N43E3E0> It's false because PCA minimizes orthogonal distance, not vertical distance
Oh okay cool thanks Julia!
Can anyone see their linear algebra quizzes?
Mine aren’t showing up anymore….
Mine says I have to take it again to see the answers.
I can't see my attempts
Ahh okay. That’s what mine is doing, too.
I was kind of worried for a bit, because the grades aren’t there anymore either.
If you take it again, does it show you what you got right and wrong?
You can't see your old answers, but if you retake the quizzes it would immediately show you what you got right and wrong.  I actually liked it because it gave me the opportunity to check what I did/didn't remember.
<@U1N43E3E0> awesome, Thanks!  That is cool, makes it more realistic
<@U1N43E3E0> <@U1L1WFNC8> this is probably a stupid question, but do you think it would overwrite our grades from when we took the quizzes previously?
<@U1L914KNJ> I hope not, but then again, I do know more now than when I took them previously haha
<@U1L914KNJ> No idea, I would ask Dr Race if you're nervous.  I ended up doing better the second time around even though I wasn't really trying as hard.
Black lives matter. Grades don't
It won't overwrite your earlier grade attempts <@U1L914KNJ>.  Also if I remember correctly, Dr. Race said they aren't graded.
so true -she did definitely say that she does not care how we do on the quizzes (I just re-heard that part in the first lecture!)
whaaaaat
wow that is such great news! Missing one question is like an 83 on those quizzes!!!
<@U1L914KNJ> I saw on Moodle that the quizzes are set to take the "first attempt" as the grade if that helps!
<!channel> I talked to dr race abt it today. Ur old grades don't disappear. Someone asked her if she could open up the quizzes in a way that they could take them again to test themselves so that's what she did 
Will we have formula sheets for the exam tomorrow?
No <@U1KSR1MS4> she said we won't have any
<@U1L9DD1NY>: thanks!
Wait nevermind got it lol 
what types of questions should we expect? i'm just going through each of the worksheets, quizzes were similar to those... any suggestions?
im reviewing both. worksheets for calculations, quizzes for more theoretical stuff
The jeopardy questions would be good too, I'm going to go through those after the worksheets and quizzes
Can someone help me understand why the jeopardy answer is true but the slides say orthogonal does not mean independent? :
If they are mutually orthogonal it is impossible to express one vector in terms of the others so they have to be independent
Interesting finding <@U1KSR1MS4> :thinking_face:
For those slides I have in my notes that orthogonal vectors are independent of each other, which means that they are completely uncorrelated. This means that they do not have a linear relationship. However, two vectors that are uncorrelated does not necessarily mean they are independent because they could have a quadratic relationship or of some other function. I think that's what she means here but the slides are confusing in format. Correct me if I am wrong  
<@U1KSR1MS4> I just rewatched that lecture and I think <@U1KSYP1M5> got it exactly right
Thanks <@U1KRLV1CG> <@U1KSYP1M5> <@U1L914KNJ>

Makes sense
Linearly independent means that the vectors cannot be expressed as a linear combination of the other vectors.  You couldn't create a vector by adding together any number of vectors that are orthogonal to it.  The use of independence in the slides refers to the statistical interpretation of independence, not linearly independent.
Does anyone know if the svd chapter is going to be tested? I know she said the big takeaway is that pca is a special case of svd but anything beyond that? 
<@U1KSR1MS4> go about 22 minutes into the second lecture for your answer.  Basically the key word is "linearly" independent.  They can still be dependent on each other in a non-linear way.
Woah sorry guys, for some reason my slack didn't update.  Didn't know that this was already answered.
<@U1KSEJ01W>, I was wondering that too, since there's no worksheet or quiz for it.
<@U1KT2JJE8> I would imagine it wont be, or maybe just one question because there was no worksheet or quiz for it, but like i said i have no idea
calling it quits...good luck tomorrow!
Remember, any answer that includes the eigenvalues of the data matrix will NOT be the right answer (because the data matrix will likely not be square).
Sooo can someone explain the difference between factor analysis and PCA? Having trouble figuring out the main difference between the two and I can't find the factor analysis slides 
you know the stuff from the factor analysis lecture is not on the test, right?
Yes just curious haha
the way I understand it, factor analysis involves rotation of the principal components to get to a basis that is more interpretable in terms of the original variables.
Rotation can be used in both PCA and FA. Here's a link to a really clear, concise article about the similarities and differences. One fundamental difference is conceptual:  that factor analysis assumes, and attempts to evaluate/measure/describe, "latent" variables that cannot be directly observed. <http://www2.sas.com/proceedings/sugi30/203-30.pdf>
Thank you! <@U1KSL7C10> 
